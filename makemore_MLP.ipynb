{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4da5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps: \n",
    "# 1. load dataset\n",
    "# 2. create mappings\n",
    "# 3. create dataset\n",
    "# 4. create emb, layers\n",
    "# 5. split the dataset\n",
    "# 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c712a37",
   "metadata": {},
   "source": [
    "# MLP for Creating Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6321cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46d355e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset:\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "be41478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle words:\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd419b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mappings:\n",
    "itos, stoi = {}, {}\n",
    "chrs = sorted(list(set(''.join(words))))\n",
    "for i, j in enumerate(chrs):\n",
    "    itos[i+1] = j\n",
    "    stoi[j] = i+1\n",
    "\n",
    "itos[0] = '.'\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "375d0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset:\n",
    "X, Y = [], []\n",
    "\n",
    "block_size = 3\n",
    "\n",
    "for word in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in word + '.':\n",
    "        X.append(context)\n",
    "        Y.append(stoi[ch])\n",
    "        context = context[1:] + [stoi[ch]]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d403765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = int(X.shape[0] * 0.8) \n",
    "vald = int(X.shape[0] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "58ac3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training, validation and test\n",
    "Xtr = X[:tr]\n",
    "Ytr = Y[:tr]\n",
    "Xvald = X[tr:vald]\n",
    "Yvald = Y[tr:vald]\n",
    "Xtest = X[vald:]\n",
    "Ytest = Y[vald:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb84af",
   "metadata": {},
   "source": [
    "## Create the Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d5420683",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2352173234)\n",
    "emb_size = 10 # num of dim used to represent a character \n",
    "\n",
    "C = torch.randn((27, emb_size), generator=g) # embeddings table\n",
    "input = C[Xtr].view(-1, block_size*emb_size) # input to the hidden layer\n",
    "\n",
    "# hidden layer\n",
    "h_neurons = 200 # number of neurons in the hidden layer\n",
    "w1 = torch.randn((block_size*emb_size, h_neurons), generator=g)\n",
    "b1 = torch.randn((h_neurons), generator=g)\n",
    "\n",
    "# final layer\n",
    "w2 = torch.randn(h_neurons, 27, generator=g)\n",
    "b2 = torch.randn(27, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "81eb1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all parameters:\n",
    "P = [C, w1, b1, w2, b2]\n",
    "for _ in P:\n",
    "    _.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "32c54561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d6c27c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop:\n",
    "for _ in range(200000):\n",
    "\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32, )) # split into batches\n",
    "    # forward pass:\n",
    "    h = torch.tanh(C[Xtr[ix]].view(-1, block_size*emb_size) @ w1 + b1)\n",
    "    logits = h @ w2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) \n",
    "\n",
    "    # backward pass:\n",
    "    for p in P:\n",
    "        p.grad = None\n",
    "    loss.backward() # None is replaced by the computd gradient\n",
    "    # print(loss.item())\n",
    "    # update:\n",
    "    lr = 0.1 if _ < 100000 else 0.01\n",
    "    for p in P:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e66d0634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1250, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating loss on training split:\n",
    "emb = C[Xtr]\n",
    "h = torch.tanh(emb.view(-1, 30) @ w1 + b1)\n",
    "logits = h @ w2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3454d936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1560, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating loss on dev split:\n",
    "emb = C[Xvald]\n",
    "h = torch.tanh(emb.view(-1, 30) @ w1 + b1)\n",
    "logits = h @ w2 + b2\n",
    "loss = F.cross_entropy(logits, Yvald)\n",
    "loss\n",
    "\n",
    "# h = 100, emb-size = 2, dev-loss = 2.52\n",
    "# h = 300, emb-size = 3, dev-loss = 2.53\n",
    "# maybe, bottle-neck is emb-size.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3ea99ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jovaryan.\n",
      "joseli.\n",
      "joneelia.\n",
      "khyimerola.\n",
      "lazattanna.\n",
      "kion.\n",
      "alligh.\n",
      "selyn.\n",
      "faryon.\n",
      "shanleiyah.\n",
      "madeigh.\n",
      "olarier.\n",
      "amianea.\n",
      "yasif.\n",
      "cyrena.\n",
      "nalidalyleel.\n",
      "jayla.\n",
      "darilielli.\n",
      "maxreeston.\n",
      "zachim.\n"
     ]
    }
   ],
   "source": [
    "# sampling from the model:\n",
    "g = torch.Generator().manual_seed(2352193234 + 10)\n",
    "for _ in range(20):\n",
    "    # begin with: ...\n",
    "    out = []\n",
    "    context = [0]*3\n",
    "\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1, -1) @ w1 + b1)\n",
    "        logits = h @ w2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
